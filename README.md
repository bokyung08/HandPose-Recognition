# HandPose Recognition (1ì¸ì¹­ ì‹¤ì‹œê°„ ì†ë™ì‘ ì¸ì‹)

ì´ í”„ë¡œì íŠ¸ëŠ” **1ì¸ì¹­ ì‹œì  ì†ë™ì‘ ì˜ìƒ**ê³¼ **MediaPipe ì† ëœë“œë§ˆí¬**ë¥¼ í•¨ê»˜ í™œìš©í•˜ì—¬  
**3D CNN (ì˜ìƒ ê¸°ë°˜) + LSTM (ëœë“œë§ˆí¬ ê¸°ë°˜) + Attention ìœµí•© ëª¨ë¸**ì„ í•™ìŠµí•˜ê³ ,  
ì‹¤ì‹œê°„ìœ¼ë¡œ ì†ë™ì‘ì„ ì¸ì‹í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

---

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ (Model Architecture)

ì´ ëª¨ë¸ì€ ì˜ìƒ í”„ë ˆì„(Video)ê³¼ ì† ì¢Œí‘œ(Landmark) ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ì¶”ë¡ í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

```mermaid
graph TD
    %% ì…ë ¥ ê³„ì¸µ
    subgraph Inputs [ì…ë ¥ ë°ì´í„°]
        VI(Video Input<br/>Shape: Seq, H, W, 1)
        LI(Landmark Input<br/>Shape: Seq, Joints*3)
    end

    %% ë¹„ë””ì˜¤ ë¸Œëœì¹˜ (3D CNN + LSTM + Attention)
    subgraph VideoBranch [Video Branch]
        VI --> C1[Conv3D 32 + MaxPool]
        C1 --> C2[Conv3D 64 + MaxPool]
        C2 --> C3[Conv3D 128 + MaxPool]
        C3 --> TDF[TimeDistributed Flatten]
        TDF --> VLSTM[LSTM 128<br/>return_sequences=True]
        VLSTM --> VAtt[Attention Layer]
        VAtt --> VContext(Video Context Vector)
    end

    %% ëœë“œë§ˆí¬ ë¸Œëœì¹˜ (LSTM + Attention)
    subgraph LandmarkBranch [Landmark Branch]
        LI --> LLSTM[LSTM 128<br/>return_sequences=True]
        LLSTM --> LAtt[Attention Layer]
        LAtt --> LContext(Landmark Context Vector)
        LContext --> LDense[Dense 128 + ReLU]
    end

    %% ê²°í•© ë° ì¶œë ¥
    subgraph Fusion [Fusion & Output]
        VContext --> Concat[Concatenate]
        LDense --> Concat
        Concat --> FDense[Dense 128 + ReLU]
        FDense --> Drop[Dropout 0.5]
        Drop --> Out[Output Layer<br/>Dense Num_Classes + Softmax]
    end

    style Inputs fill:#f9f,stroke:#333,stroke-width:2px
    style VideoBranch fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style LandmarkBranch fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style Fusion fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
```

Video Branch: 3D CNNì„ í†µí•´ ì˜ìƒì˜ ì‹œê³µê°„ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³ , LSTMê³¼ Attentionì„ í†µí•´ ì¤‘ìš”í•œ í”„ë ˆì„ ì •ë³´ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

Landmark Branch: MediaPipeë¡œ ì¶”ì¶œëœ ì† ê´€ì ˆ ì¢Œí‘œì˜ ì‹œê³„ì—´ ë³€í™”ë¥¼ LSTMê³¼ Attentionìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

Fusion: ë‘ ê°€ì§€ ì •ë³´ë¥¼ ê²°í•©(Concatenate)í•˜ì—¬ ìµœì¢… ì œìŠ¤ì²˜ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°
```

handpose-recognition/
â”‚â”€â”€ README.md               # í”„ë¡œì íŠ¸ ì„¤ëª… ë° ëª¨ë¸ êµ¬ì¡°
â”‚â”€â”€ requirements.txt        # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡
â”‚â”€â”€ config.py               # ê³µí†µ ì„¤ì • (Sequence Length, Image Size ë“±)
â”‚
â”œâ”€â”€ data/                   # ë°ì´í„° ì €ì¥ í´ë”
â”‚   â””â”€â”€ raw/                # ì›ë³¸ ì˜ìƒ ë°ì´í„° (í´ë˜ìŠ¤ë³„ í´ë”)
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ data_loader.py      # ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬ (Generator)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ attention_layer.py  # Custom Attention ë ˆì´ì–´ ì •ì˜
â”‚   â”œâ”€â”€ multimodal_model.py # (3D CNN + LSTM + Attention) ìœµí•© ëª¨ë¸
â”‚   â””â”€â”€ multimodal_model_3d.py # (êµ¬ë²„ì „/ëŒ€ì²´ ëª¨ë¸ ë“±)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ mediapipe_utils.py  # MediaPipe í—¬í¼ í•¨ìˆ˜ (ëœë“œë§ˆí¬ ì¶”ì¶œ)
â”‚   â”œâ”€â”€ visualization.py    # ì‹œê°í™” í•¨ìˆ˜ (í•™ìŠµê³¡ì„ , í˜¼ë™í–‰ë ¬)
â”‚
â”œâ”€â”€ train.py                # ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ evaluate.py             # ëª¨ë¸ í‰ê°€ (ë¦¬í¬íŠ¸ & confusion matrix ì €ì¥)
â””â”€â”€ inference.py            # ì‹¤ì‹œê°„ ì›¹ìº  ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
```
